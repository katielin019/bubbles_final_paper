{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import cleaner\n",
    "from scripts import entro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decades = ['1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
    "decades_dict = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~#### Read src csv lists to df's~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Takes in one of the decade CSV show lists and returns it as a formatted dataframe\n",
    "# def csvToDataframe(filename):\n",
    "#     df = pd.read_csv(filename, header=None, names=['title', 'start', 'end', 'wiki_url', 'transcript_url'])\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for decade in decades:\n",
    "#     path = \"src/\" + decade[:-1] + \"_shows.csv\"\n",
    "#     decades_dict[decade] = csvToDataframe(path)\n",
    "#     # print(path + \" has been processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows = []\n",
    "# for decade in decades:\n",
    "#     curr_df = decades_dict[decade]\n",
    "#     for i, row in curr_df.iterrows():\n",
    "#         shows.append(row['title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read metadata csv's to df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for decade in decades:\n",
    "    path = \"metadata/episodes_\" + decade[:-1] + \".csv\"\n",
    "    meta[decade] = pd.read_csv(path, header=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group df's by title and season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for decade in decades:\n",
    "    curr_df = meta[decade]\n",
    "    meta[decade] = curr_df.groupby(['title', 'season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        season\n",
       "I Love Lucy  1         36\n",
       "             2         32\n",
       "             3         31\n",
       "             4         30\n",
       "             5         26\n",
       "             6         27\n",
       "Name: episode, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['1950s']['episode'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                  season\n",
       "30 Rock                1         21\n",
       "                       2         15\n",
       "                       3         22\n",
       "                       4         21\n",
       "                       5         22\n",
       "                       6         21\n",
       "                       7         12\n",
       "Big Bang Theory        1         17\n",
       "                       2         23\n",
       "                       3         23\n",
       "                       4         24\n",
       "                       5         24\n",
       "                       6         24\n",
       "                       7         24\n",
       "                       8         24\n",
       "                       9         24\n",
       "                       10        24\n",
       "                       11        24\n",
       "                       12        24\n",
       "Community              1         25\n",
       "                       2         24\n",
       "                       3         22\n",
       "                       4         13\n",
       "                       5         13\n",
       "                       6         13\n",
       "Malcolm in the Middle  1         16\n",
       "                       2         25\n",
       "                       3         22\n",
       "                       4         22\n",
       "                       5         22\n",
       "                       6         22\n",
       "                       7         22\n",
       "Parks and Recreation   1          6\n",
       "                       2         24\n",
       "                       3         16\n",
       "                       4         22\n",
       "                       5         22\n",
       "                       6         20\n",
       "                       7         12\n",
       "Psych                  1         15\n",
       "                       2         16\n",
       "                       3         16\n",
       "                       4         16\n",
       "                       5         16\n",
       "                       6         16\n",
       "                       7         15\n",
       "                       8         10\n",
       "The IT Crowd           1          6\n",
       "                       2          6\n",
       "                       3          6\n",
       "                       4          7\n",
       "The Office (US)        1          6\n",
       "                       2         22\n",
       "                       3         23\n",
       "                       4         14\n",
       "                       5         26\n",
       "                       6         24\n",
       "                       7         24\n",
       "                       8         24\n",
       "                       9         23\n",
       "Name: episode, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['2000s']['episode'].count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mark = \"{START OF EPISODE \"\n",
    "z_mark = \"{END OF EPISODE \"\n",
    "base = \"https://www.springfieldspringfield.co.uk/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for getTV()\n",
    "def getScript(url):\n",
    "    # Returns list of lines from episode transcript\n",
    "    page = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    text = soup.find(\"div\", {\"class\":\"scrolling-script-container\"}).get_text()\n",
    "    cleaned = cleaner.clean(text)\n",
    "    return cleaned\n",
    "    # return cleaner.split_into_sentences(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in decade as a string value (the key for the current decade we're scraping)\n",
    "def getTV(decade):\n",
    "    for grp_idx, grp in meta[decade]:\n",
    "        t_raw, season, ended = grp_idx[0], grp_idx[1], False\n",
    "        if season < 7:\n",
    "            t_clean = re.sub(r' ', '_', t_raw.lower())\n",
    "            f_path = \"transcripts/\" + decade + \"/\" + t_clean + \"_season\" + str(season) + \".txt\"\n",
    "            # open file to begin writing\n",
    "            f = open(f_path, \"w\")\n",
    "            print(\"Currently scraping... \" + t_raw + \", Season \" + str(season))\n",
    "            # loop through each episode of the current season\n",
    "            for row_idx, row in grp.iterrows():\n",
    "                # add episode start marker\n",
    "                f.write(a_mark + str(row['episode']) + \"}\" + \"\\n\")\n",
    "                # get transcript\n",
    "                text = getScript(base + row['url'])\n",
    "                lines = cleaner.split_into_sentences(text)\n",
    "                # add each line to the file\n",
    "                for i in range(len(lines)):\n",
    "                    f.write(lines[i])\n",
    "                    if i < len(lines) - 1:\n",
    "                        f.write(\"\\n\")\n",
    "                # add episode end marker\n",
    "                f.write(\"\\n\" + z_mark + str(row['episode']) + \"}\")\n",
    "            # close the file !!!\n",
    "            f.close()\n",
    "            print(\"Finished scraping... \" + t_raw + \", Season \" + str(season))\n",
    "        else:\n",
    "            if not ended:\n",
    "                print(\"Yeah I'm not scraping past 6 seasons bud... sorry.\") #SixSeasonsAndAMovie\n",
    "                ended = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently scraping... I Love Lucy, Season 1\n",
      "Finished scraping... I Love Lucy, Season 1\n",
      "Currently scraping... I Love Lucy, Season 2\n",
      "Finished scraping... I Love Lucy, Season 2\n",
      "Currently scraping... I Love Lucy, Season 3\n",
      "Finished scraping... I Love Lucy, Season 3\n",
      "Currently scraping... I Love Lucy, Season 4\n",
      "Finished scraping... I Love Lucy, Season 4\n",
      "Currently scraping... I Love Lucy, Season 5\n",
      "Finished scraping... I Love Lucy, Season 5\n",
      "Currently scraping... I Love Lucy, Season 6\n",
      "Finished scraping... I Love Lucy, Season 6\n"
     ]
    }
   ],
   "source": [
    "getTV('1950s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently scraping... M*A*S*H, Season 1\n",
      "Finished scraping... M*A*S*H, Season 1\n",
      "Currently scraping... M*A*S*H, Season 2\n",
      "Finished scraping... M*A*S*H, Season 2\n",
      "Currently scraping... M*A*S*H, Season 3\n",
      "Finished scraping... M*A*S*H, Season 3\n",
      "Currently scraping... M*A*S*H, Season 4\n",
      "Finished scraping... M*A*S*H, Season 4\n",
      "Currently scraping... M*A*S*H, Season 5\n",
      "Finished scraping... M*A*S*H, Season 5\n",
      "Currently scraping... M*A*S*H, Season 6\n",
      "Finished scraping... M*A*S*H, Season 6\n",
      "Yeah I'm not scraping past 6 seasons bud... sorry.\n",
      "Yeah I'm not scraping past 6 seasons bud... sorry.\n",
      "Yeah I'm not scraping past 6 seasons bud... sorry.\n",
      "Yeah I'm not scraping past 6 seasons bud... sorry.\n",
      "Yeah I'm not scraping past 6 seasons bud... sorry.\n",
      "Currently scraping... Mork and Mindy, Season 1\n",
      "Finished scraping... Mork and Mindy, Season 1\n",
      "Currently scraping... Mork and Mindy, Season 2\n",
      "Finished scraping... Mork and Mindy, Season 2\n",
      "Currently scraping... Mork and Mindy, Season 3\n",
      "Finished scraping... Mork and Mindy, Season 3\n",
      "Currently scraping... Mork and Mindy, Season 4\n",
      "Finished scraping... Mork and Mindy, Season 4\n",
      "Currently scraping... Sanford and Son, Season 1\n",
      "Finished scraping... Sanford and Son, Season 1\n",
      "Currently scraping... Sanford and Son, Season 2\n",
      "Finished scraping... Sanford and Son, Season 2\n",
      "Currently scraping... Taxi, Season 1\n",
      "Finished scraping... Taxi, Season 1\n",
      "Currently scraping... Taxi, Season 2\n",
      "Finished scraping... Taxi, Season 2\n",
      "Currently scraping... Taxi, Season 3\n"
     ]
    }
   ],
   "source": [
    "getTV('1970s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'\\{START OF EPISODE \\d{2}\\}(.+?)\\{END OF EPISODE \\d{2}\\}', re.DOTALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
