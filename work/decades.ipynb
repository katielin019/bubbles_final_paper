{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "decades = ['1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
    "decades_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in one of the decade CSV show lists and returns it as a formatted dataframe\n",
    "def csvToDataframe(filename):\n",
    "    df = pd.read_csv(filename, header=None, names=['title', 'start', 'end', 'wiki_url', 'transcript_url'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src/1950_shows.csv has been processed\n",
      "src/1960_shows.csv has been processed\n",
      "src/1970_shows.csv has been processed\n",
      "src/1980_shows.csv has been processed\n",
      "src/1990_shows.csv has been processed\n",
      "src/2000_shows.csv has been processed\n",
      "src/2010_shows.csv has been processed\n"
     ]
    }
   ],
   "source": [
    "for decade in decades:\n",
    "    path = \"src/\" + decade[:-1] + \"_shows.csv\"\n",
    "    decades_dict[decade] = csvToDataframe(path)\n",
    "    print(path + \" has been processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1950s':          title      start       end  \\\n",
      "0  I Love Lucy  Oct. 1951  May 1957   \n",
      "\n",
      "                                    wiki_url  \\\n",
      "0  https://en.wikipedia.org/wiki/I_Love_Lucy   \n",
      "\n",
      "                                      transcript_url  \n",
      "0  https://www.springfieldspringfield.co.uk/episo...  , '1960s':                 title      start        end  \\\n",
      "0     The Flintstones  Sep. 1960  Apr. 1966   \n",
      "1           Bewitched  Sep. 1964  Mar. 1972   \n",
      "2   The Addams Family  Sep. 1964  Apr. 1966   \n",
      "3        The Munsters  Sep. 1964   May 1966   \n",
      "4           Get Smart  Sep. 1965   May 1970   \n",
      "5  I Dream of Jeannie  Sep. 1965   May 1970   \n",
      "\n",
      "                                            wiki_url  \\\n",
      "0      https://en.wikipedia.org/wiki/The_Flintstones   \n",
      "1            https://en.wikipedia.org/wiki/Bewitched   \n",
      "2  https://en.wikipedia.org/wiki/The_Addams_Famil...   \n",
      "3         https://en.wikipedia.org/wiki/The_Munsters   \n",
      "4            https://en.wikipedia.org/wiki/Get_Smart   \n",
      "5   https://en.wikipedia.org/wiki/I_Dream_of_Jeannie   \n",
      "\n",
      "                                      transcript_url  \n",
      "0  https://www.springfieldspringfield.co.uk/episo...  \n",
      "1  https://www.springfieldspringfield.co.uk/episo...  \n",
      "2  https://www.springfieldspringfield.co.uk/episo...  \n",
      "3  https://www.springfieldspringfield.co.uk/episo...  \n",
      "4  https://www.springfieldspringfield.co.uk/episo...  \n",
      "5  https://www.springfieldspringfield.co.uk/episo...  , '1970s':                        title      start        end  \\\n",
      "0  The Mary Tyler Moore Show  Sep. 1970  Mar. 1977   \n",
      "1            Sanford and Son  Jan. 1972  Mar. 1977   \n",
      "2                    M*A*S*H  Sep. 1972  Feb. 1983   \n",
      "3            Three's Company  Mar. 1977  Sep. 1984   \n",
      "4             Mork and Mindy  Sep. 1978   May 1982   \n",
      "5                       Taxi  Sep. 1978  Jun. 1983   \n",
      "\n",
      "                                            wiki_url  \\\n",
      "0  https://en.wikipedia.org/wiki/The_Mary_Tyler_M...   \n",
      "1      https://en.wikipedia.org/wiki/Sanford_and_Son   \n",
      "2  https://en.wikipedia.org/wiki/M*A*S*H_(TV_series)   \n",
      "3    https://en.wikipedia.org/wiki/Three%27s_Company   \n",
      "4       https://en.wikipedia.org/wiki/Mork_%26_Mindy   \n",
      "5     https://en.wikipedia.org/wiki/Taxi_(TV_series)   \n",
      "\n",
      "                                      transcript_url  \n",
      "0  https://www.springfieldspringfield.co.uk/episo...  \n",
      "1  https://www.springfieldspringfield.co.uk/episo...  \n",
      "2  https://www.springfieldspringfield.co.uk/episo...  \n",
      "3  https://www.springfieldspringfield.co.uk/episo...  \n",
      "4  https://www.springfieldspringfield.co.uk/episo...  \n",
      "5  https://www.springfieldspringfield.co.uk/episo...  , '1980s':                title      start        end  \\\n",
      "0             Cheers  Sep. 1982   May 1993   \n",
      "1    Who's the Boss?  Sep. 1984  Apr. 1992   \n",
      "2   The Golden Girls  Sep. 1985   May 1992   \n",
      "3         Full House  Sep. 1987   May 1995   \n",
      "4           Seinfeld  Jul. 1989   May 1998   \n",
      "5  Saved By The Bell  Aug. 1989   May 1993   \n",
      "\n",
      "                                            wiki_url  \\\n",
      "0               https://en.wikipedia.org/wiki/Cheers   \n",
      "1  https://en.wikipedia.org/wiki/Who%27s_the_Boss%3F   \n",
      "2     https://en.wikipedia.org/wiki/The_Golden_Girls   \n",
      "3           https://en.wikipedia.org/wiki/Full_House   \n",
      "4             https://en.wikipedia.org/wiki/Seinfeld   \n",
      "5    https://en.wikipedia.org/wiki/Saved_by_the_Bell   \n",
      "\n",
      "                                      transcript_url  \n",
      "0  https://www.springfieldspringfield.co.uk/episo...  \n",
      "1  https://www.springfieldspringfield.co.uk/episo...  \n",
      "2  https://www.springfieldspringfield.co.uk/episo...  \n",
      "3  https://www.springfieldspringfield.co.uk/episo...  \n",
      "4  https://www.springfieldspringfield.co.uk/episo...  \n",
      "5  https://www.springfieldspringfield.co.uk/episo...  , '1990s':                          title      start        end  \\\n",
      "0  The Fresh Prince of Bel-Air  Sep. 1990   May 1996   \n",
      "1              Boy Meets World  Sep. 1993   May 2000   \n",
      "2                      Frasier  Sep. 1993   May 2004   \n",
      "3                      Friends  Sep. 1994   May 2004   \n",
      "4    Sabrina The Teenage Witch  Sep. 1996  Apr. 2003   \n",
      "5     Buffy the Vampire Slayer  Mar. 1997   May 2003   \n",
      "6               That '70s Show  Aug. 1998   May 2006   \n",
      "7                 Will & Grace  Sep. 1998   May 2006   \n",
      "\n",
      "                                            wiki_url  \\\n",
      "0  https://en.wikipedia.org/wiki/The_Fresh_Prince...   \n",
      "1      https://en.wikipedia.org/wiki/Boy_Meets_World   \n",
      "2              https://en.wikipedia.org/wiki/Frasier   \n",
      "3              https://en.wikipedia.org/wiki/Friends   \n",
      "4  https://en.wikipedia.org/wiki/Sabrina_the_Teen...   \n",
      "5  https://en.wikipedia.org/wiki/Buffy_the_Vampir...   \n",
      "6     https://en.wikipedia.org/wiki/That_%2770s_Show   \n",
      "7       https://en.wikipedia.org/wiki/Will_%26_Grace   \n",
      "\n",
      "                                      transcript_url  \n",
      "0  https://www.springfieldspringfield.co.uk/episo...  \n",
      "1  https://www.springfieldspringfield.co.uk/episo...  \n",
      "2  https://www.springfieldspringfield.co.uk/episo...  \n",
      "3  https://www.springfieldspringfield.co.uk/episo...  \n",
      "4  https://www.springfieldspringfield.co.uk/episo...  \n",
      "5  https://www.springfieldspringfield.co.uk/episo...  \n",
      "6  https://www.springfieldspringfield.co.uk/episo...  \n",
      "7  https://www.springfieldspringfield.co.uk/episo...  , '2000s':                    title      start        end  \\\n",
      "0  Malcolm in the Middle  Jan. 2000   May 2006   \n",
      "1        The Office (US)  Mar. 2005   May 2013   \n",
      "2           The IT Crowd  Feb. 2006  Sep. 2013   \n",
      "3                  Psych  Jul. 2006  Mar. 2014   \n",
      "4                30 Rock  Oct. 2006  Jan. 2013   \n",
      "5        Big Bang Theory  Sep. 2007   May 2019   \n",
      "6   Parks and Recreation  Apr. 2009  Feb. 2015   \n",
      "7              Community  Sep. 2009  Jun. 2015   \n",
      "\n",
      "                                            wiki_url  \\\n",
      "0  https://en.wikipedia.org/wiki/Malcolm_in_the_M...   \n",
      "1  https://en.wikipedia.org/wiki/The_Office_(Amer...   \n",
      "2         https://en.wikipedia.org/wiki/The_IT_Crowd   \n",
      "3                https://en.wikipedia.org/wiki/Psych   \n",
      "4              https://en.wikipedia.org/wiki/30_Rock   \n",
      "5  https://en.wikipedia.org/wiki/The_Big_Bang_Theory   \n",
      "6  https://en.wikipedia.org/wiki/Parks_and_Recrea...   \n",
      "7  https://en.wikipedia.org/wiki/Community_(TV_se...   \n",
      "\n",
      "                                      transcript_url  \n",
      "0  https://www.springfieldspringfield.co.uk/episo...  \n",
      "1  https://www.springfieldspringfield.co.uk/episo...  \n",
      "2  https://www.springfieldspringfield.co.uk/episo...  \n",
      "3  https://www.springfieldspringfield.co.uk/episo...  \n",
      "4  https://www.springfieldspringfield.co.uk/episo...  \n",
      "5  https://www.springfieldspringfield.co.uk/episo...  \n",
      "6  https://www.springfieldspringfield.co.uk/episo...  \n",
      "7  https://www.springfieldspringfield.co.uk/episo...  , '2010s':                 title      start        end  \\\n",
      "0            New Girl  Sep. 2011   May 2018   \n",
      "1  Brooklyn Nine-Nine  Sep. 2013  Sep. 2021   \n",
      "2      Silicon Valley  Apr. 2014  Dec. 2019   \n",
      "3      Schitt's Creek  Jan. 2015  Apr. 2020   \n",
      "4             Fleabag  Jul. 2016  Apr. 2019   \n",
      "5      The Good Place  Sep. 2016  Jan. 2020   \n",
      "6  Santa Clarita Diet  Feb. 2017  Mar. 2019   \n",
      "7               PEN15  Feb. 2019  Dec. 2021   \n",
      "\n",
      "                                            wiki_url  \\\n",
      "0             https://en.wikipedia.org/wiki/New_Girl   \n",
      "1   https://en.wikipedia.org/wiki/Brooklyn_Nine-Nine   \n",
      "2  https://en.wikipedia.org/wiki/Silicon_Valley_(...   \n",
      "3     https://en.wikipedia.org/wiki/Schitt%27s_Creek   \n",
      "4              https://en.wikipedia.org/wiki/Fleabag   \n",
      "5       https://en.wikipedia.org/wiki/The_Good_Place   \n",
      "6   https://en.wikipedia.org/wiki/Santa_Clarita_Diet   \n",
      "7                https://en.wikipedia.org/wiki/PEN15   \n",
      "\n",
      "                                      transcript_url  \n",
      "0  https://www.springfieldspringfield.co.uk/episo...  \n",
      "1  https://www.springfieldspringfield.co.uk/episo...  \n",
      "2  https://www.springfieldspringfield.co.uk/episo...  \n",
      "3  https://www.springfieldspringfield.co.uk/episo...  \n",
      "4  https://www.springfieldspringfield.co.uk/episo...  \n",
      "5  https://www.springfieldspringfield.co.uk/episo...  \n",
      "6  https://www.springfieldspringfield.co.uk/episo...  \n",
      "7  https://www.springfieldspringfield.co.uk/episo...  }\n"
     ]
    }
   ],
   "source": [
    "print(decades_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows = []\n",
    "for decade in decades:\n",
    "    curr_df = decades_dict[decade]\n",
    "    for i, row in curr_df.iterrows():\n",
    "        shows.append(row['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "print(len(shows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov|edu|me)\"\n",
    "digits = \"([0-9])\"\n",
    "multiple_dots = r'\\.{2,}'\n",
    "\n",
    "def split_into_sentences(text) -> list:\n",
    "    \"\"\"\n",
    "    Split the text into sentences.\n",
    "\n",
    "    If the text contains substrings \"<prd>\" or \"<stop>\", they would lead \n",
    "    to incorrect splitting because they are used as markers for splitting.\n",
    "\n",
    "    :param text: text to be split into sentences\n",
    "    :type text: str\n",
    "\n",
    "    :return: list of sentences\n",
    "    :rtype: list[str]\n",
    "    \"\"\"\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "    text = re.sub(multiple_dots, lambda match: \"<prd>\" * len(match.group(0)) + \"<stop>\", text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    if sentences and not sentences[-1]: sentences = sentences[:-1]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(txt):\n",
    "    stripped_txt = re.sub(r' +', ' ', txt)\n",
    "    transcript = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", stripped_txt)\n",
    "    remove_upper = re.sub(r'\\b[A-Z]+\\b\\:', '', transcript)\n",
    "    sep = os.linesep.join([s for s in remove_upper.splitlines() if s])\n",
    "    result = split_into_lines(sep)\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = 01\n",
      "e = 14\n"
     ]
    }
   ],
   "source": [
    "seid = \"s01e14\"\n",
    "print(\"s = \" + seid[1:3])\n",
    "print(\"e = \" + seid[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a dataframe with the columns 'title' and 'transcript_url'\n",
    "# Processes all shows in the dataframe, getting their episode urls, SEID's, and respective season and episode numbers\n",
    "# Returns this data as a new dataframe dictionary, with the key being the show's title\n",
    "# (this df will be used for populating each season's corpus, which will be placed inside the respective decade folder)\n",
    "# (so this should be organized by decade)\n",
    "def getEpisodes(df):\n",
    "    result = pd.DataFrame(columns=['title', 'season', 'episode', 'url', 'seid'])\n",
    "    for idx, row in df.iterrows():\n",
    "        curr_show, curr_url = row['title'], row['transcript_url']\n",
    "        page = urllib.request.urlopen(curr_url)\n",
    "        soup = BeautifulSoup(page, \"lxml\")\n",
    "        seid_list, s_list, e_list = [], [], []\n",
    "        url_list = []\n",
    "\n",
    "        for link in soup.find_all('a'):\n",
    "            route = link.get('href')\n",
    "            if route.startswith(\"view_episode_scripts\"):\n",
    "                seid = route[-6:]\n",
    "                seid_list.append(seid)\n",
    "                s_list.append(seid[1:3])\n",
    "                e_list.append(seid[4:])\n",
    "                url_list.append(route)\n",
    "        show = pd.DataFrame(columns=['title', 'season', 'episode', 'url', 'seid'])\n",
    "        show['seid'] = seid_list\n",
    "        show['url'] = url_list\n",
    "        show['episode'] = e_list\n",
    "        show['season'] = s_list\n",
    "        show['title'] = curr_show\n",
    "        result = result.append(show, ignore_index=True)\n",
    "    return result\n",
    "        \n",
    "    # return pd.DataFrame({'season': s_list, 'episode': e_list, 'url': url_list, 'seid': seid_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_1950 = getEpisodes(decades_dict['1950s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>url</th>\n",
       "      <th>seid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>I Love Lucy</td>\n",
       "      <td>05</td>\n",
       "      <td>02</td>\n",
       "      <td>view_episode_scripts.php?tv-show=i-love-lucy-1...</td>\n",
       "      <td>s05e02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I Love Lucy</td>\n",
       "      <td>01</td>\n",
       "      <td>16</td>\n",
       "      <td>view_episode_scripts.php?tv-show=i-love-lucy-1...</td>\n",
       "      <td>s01e16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I Love Lucy</td>\n",
       "      <td>03</td>\n",
       "      <td>28</td>\n",
       "      <td>view_episode_scripts.php?tv-show=i-love-lucy-1...</td>\n",
       "      <td>s03e28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>I Love Lucy</td>\n",
       "      <td>06</td>\n",
       "      <td>22</td>\n",
       "      <td>view_episode_scripts.php?tv-show=i-love-lucy-1...</td>\n",
       "      <td>s06e22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I Love Lucy</td>\n",
       "      <td>01</td>\n",
       "      <td>10</td>\n",
       "      <td>view_episode_scripts.php?tv-show=i-love-lucy-1...</td>\n",
       "      <td>s01e10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title season episode  \\\n",
       "130  I Love Lucy     05      02   \n",
       "16   I Love Lucy     01      16   \n",
       "95   I Love Lucy     03      28   \n",
       "176  I Love Lucy     06      22   \n",
       "10   I Love Lucy     01      10   \n",
       "\n",
       "                                                   url    seid  \n",
       "130  view_episode_scripts.php?tv-show=i-love-lucy-1...  s05e02  \n",
       "16   view_episode_scripts.php?tv-show=i-love-lucy-1...  s01e16  \n",
       "95   view_episode_scripts.php?tv-show=i-love-lucy-1...  s03e28  \n",
       "176  view_episode_scripts.php?tv-show=i-love-lucy-1...  s06e22  \n",
       "10   view_episode_scripts.php?tv-show=i-love-lucy-1...  s01e10  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_1950.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_1960 = getEpisodes(decades_dict['1960s'])\n",
    "episodes_1970 = getEpisodes(decades_dict['1970s'])\n",
    "episodes_1980 = getEpisodes(decades_dict['1980s'])\n",
    "episodes_1990 = getEpisodes(decades_dict['1990s'])\n",
    "episodes_2000 = getEpisodes(decades_dict['2000s'])\n",
    "episodes_2010 = getEpisodes(decades_dict['2010s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_1950.name = 'episodes_1950'\n",
    "episodes_1960.name = 'episodes_1960'\n",
    "episodes_1970.name = 'episodes_1970'\n",
    "episodes_1980.name = 'episodes_1980'\n",
    "episodes_1990.name = 'episodes_1990'\n",
    "episodes_2000.name = 'episodes_2000'\n",
    "episodes_2010.name = 'episodes_2010'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv = [episodes_1950, episodes_1960, episodes_1970, episodes_1980, episodes_1990, episodes_2000, episodes_2010]\n",
    "\n",
    "for d in to_csv:\n",
    "    filename = d.name + '.csv'\n",
    "    d.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get transcripts():\n",
    "\n",
    "#base = \"https://www.springfieldspringfield.co.uk/\"\n",
    "        # curr_show, curr_url = row['title'], base + row['transcript_url']\n",
    "        # response = urllib.request.urlopen(curr_url)\n",
    "        # soup = BeautifulSoup(response, 'html.parser')\n",
    "        # raw_txt = soup.find(\"div\", {\"class\":\"scrolling-script-container\"}).get_text()\n",
    "        # transcript = clean(raw_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
